{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers, callbacks\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Embedding, Conv1D, Flatten, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'C:\\\\Users\\\\mgtub\\\\PycharmProjects\\\\CNN_SENTIMENT_CLASSIFIER\\\\aclImdb'\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "labels = list()\n",
    "texts = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-Processing:\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(training_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "maxlen = 500\n",
    "training_samples = 10000\n",
    "validation_samples = 10000\n",
    "max_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir='log_dir_m1',\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens. \n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens. ' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (25000, 500)\n",
      "Shape of data tensor:  (25000, 500)\n",
      "Shape of label tensor:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "data = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "print('Data shape: {}' .format(data.shape))\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor: ', data.shape)\n",
    "print('Shape of label tensor: ', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "train_data = data[:training_samples]\n",
    "train_labels = labels[:training_samples]\n",
    "\n",
    "val_data = data[training_samples:training_samples + validation_samples]\n",
    "val_labels = labels[training_samples:training_samples + validation_samples]\n",
    "\n",
    "test_data = data[training_samples + validation_samples:]\n",
    "test_labels = labels[training_samples + validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 500, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 498, 256)          38656     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 166, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 164, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 54, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 52, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 17, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,392,161\n",
      "Trainable params: 1,392,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.6974 - accuracy: 0.5056 - val_loss: 0.6916 - val_accuracy: 0.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 00:31:25.558686  9756 deprecation_wrapper.py:119] From C:\\Users\\mgtub\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.5407 - accuracy: 0.7385 - val_loss: 0.7705 - val_accuracy: 0.6375\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.3489 - accuracy: 0.8597 - val_loss: 0.3768 - val_accuracy: 0.8367\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 0.2493 - accuracy: 0.9025 - val_loss: 0.5116 - val_accuracy: 0.8132\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.2015 - accuracy: 0.9254 - val_loss: 0.3716 - val_accuracy: 0.8582\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.1525 - accuracy: 0.9471 - val_loss: 0.5854 - val_accuracy: 0.8166\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.1159 - accuracy: 0.9610 - val_loss: 0.4363 - val_accuracy: 0.8497\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 0.1018 - accuracy: 0.9653 - val_loss: 0.4519 - val_accuracy: 0.8378\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 3s 255us/step - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.7542 - val_accuracy: 0.8369\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 0.6891 - val_accuracy: 0.8413\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.0515 - accuracy: 0.9876 - val_loss: 0.8139 - val_accuracy: 0.8406\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 3s 259us/step - loss: 0.0734 - accuracy: 0.9916 - val_loss: 1.1055 - val_accuracy: 0.8344\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.0457 - accuracy: 0.9923 - val_loss: 1.4620 - val_accuracy: 0.8349\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 3s 264us/step - loss: 0.0711 - accuracy: 0.9926 - val_loss: 1.5502 - val_accuracy: 0.8324\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 3s 265us/step - loss: 0.0302 - accuracy: 0.9954 - val_loss: 1.4003 - val_accuracy: 0.8116\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.0671 - accuracy: 0.9943 - val_loss: 1.2643 - val_accuracy: 0.8320\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 0.0501 - accuracy: 0.9950 - val_loss: 1.3890 - val_accuracy: 0.8295\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.0354 - accuracy: 0.9952 - val_loss: 1.1431 - val_accuracy: 0.8279\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.0548 - accuracy: 0.9938 - val_loss: 1.3418 - val_accuracy: 0.8295\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.0606 - accuracy: 0.9948 - val_loss: 1.5313 - val_accuracy: 0.8264\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 7.7065e-04 - accuracy: 0.9997 - val_loss: 2.0972 - val_accuracy: 0.8264\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 7.9531e-04 - accuracy: 0.9997 - val_loss: 2.9194 - val_accuracy: 0.8265\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.1197 - accuracy: 0.9958 - val_loss: 3.1119 - val_accuracy: 0.8258\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 9.1586e-04 - accuracy: 0.9996 - val_loss: 2.9473 - val_accuracy: 0.8275\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 6.0878e-04 - accuracy: 0.9997 - val_loss: 3.1386 - val_accuracy: 0.8265\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.1358 - accuracy: 0.9945 - val_loss: 3.0370 - val_accuracy: 0.8213\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 6.4090e-04 - accuracy: 0.9997 - val_loss: 2.8608 - val_accuracy: 0.8285\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 6.0102e-04 - accuracy: 0.9997 - val_loss: 3.1385 - val_accuracy: 0.8275\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 3s 255us/step - loss: 0.1000 - accuracy: 0.9946 - val_loss: 3.2682 - val_accuracy: 0.8266\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 5.5930e-04 - accuracy: 0.9997 - val_loss: 2.9956 - val_accuracy: 0.8297\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 4.7799e-04 - accuracy: 0.9998 - val_loss: 3.2380 - val_accuracy: 0.8299\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 3s 264us/step - loss: 4.8325e-04 - accuracy: 0.9998 - val_loss: 3.8017 - val_accuracy: 0.8306\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 0.0476 - accuracy: 0.9972 - val_loss: 2.6761 - val_accuracy: 0.8283\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 5.2098e-04 - accuracy: 0.9998 - val_loss: 2.6540 - val_accuracy: 0.8290\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 5.3868e-04 - accuracy: 0.9998 - val_loss: 2.8153 - val_accuracy: 0.8290\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 5.4555e-04 - accuracy: 0.9998 - val_loss: 3.5469 - val_accuracy: 0.8297\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 3s 251us/step - loss: 0.0454 - accuracy: 0.9959 - val_loss: 2.4679 - val_accuracy: 0.8276\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 5.7830e-04 - accuracy: 0.9998 - val_loss: 2.6905 - val_accuracy: 0.8293\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 7.4656e-04 - accuracy: 0.9998 - val_loss: 2.9250 - val_accuracy: 0.8292\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 3s 270us/step - loss: 5.5852e-04 - accuracy: 0.9998 - val_loss: 3.9354 - val_accuracy: 0.8274\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 3s 271us/step - loss: 6.8132e-04 - accuracy: 0.9998 - val_loss: 3.9033 - val_accuracy: 0.8288\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 5.4743e-04 - accuracy: 0.9998 - val_loss: 3.9039 - val_accuracy: 0.8287\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 0.0409 - accuracy: 0.9964 - val_loss: 2.4447 - val_accuracy: 0.8268\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 4.6133e-04 - accuracy: 0.9998 - val_loss: 2.6888 - val_accuracy: 0.8286\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 7.7285e-04 - accuracy: 0.9998 - val_loss: 3.0213 - val_accuracy: 0.8271\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.0432 - accuracy: 0.9964 - val_loss: 2.7917 - val_accuracy: 0.8287\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 4.4263e-04 - accuracy: 0.9998 - val_loss: 3.0067 - val_accuracy: 0.8312\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 5.1888e-04 - accuracy: 0.9998 - val_loss: 2.9330 - val_accuracy: 0.8282\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.0924 - accuracy: 0.9950 - val_loss: 2.4083 - val_accuracy: 0.8285\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 3s 255us/step - loss: 5.1367e-04 - accuracy: 0.9998 - val_loss: 2.4078 - val_accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "\n",
    "text_input_layer = Input(shape=(500,))\n",
    "embedding_layer = Embedding(max_words, 50)(text_input_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(embedding_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = GlobalMaxPooling1D()(text_layer)\n",
    "text_layer = Dense(256, activation='relu')(text_layer)\n",
    "text_layer = Dropout(0.6)(text_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(text_layer)\n",
    "model = Model(text_input_layer, output_layer)\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=50, batch_size=128, callbacks=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
